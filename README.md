## Поиск изображения по текстовому описанию
Наши пользователи размещают свои фотографии на хостинге и сопровождают их полным описанием: указывают место съёмок, модель камеры и т. д. Отличительная особенность сервиса — описание: его может предоставить не только тот, кто размещает фотографию, но и другие пользователи портала.

Необходимо разработать демонстрационную версию поиска изображений по текстовому запросу.<br>
Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.

### Юридические ограничения

В некоторых странах, где работает компания "Со смыслом", действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно, текстов, изображений, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16-ти лет.

Поэтому необходимо очистить данные от проблемного контента. Во время тестирования модели при появлении в запросе “вредного” контента должен отображаться дисклеймер.

### Описание данных

В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.

В папке `train_images` содержатся изображения для тренировки модели.

В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:

1. Имя файла изображения.
2. Идентификатор описания.
3. Доля людей, подтвердивших, что описание соответствует изображению.
4. Количество человек, подтвердивших, что описание соответствует изображению.
5. Количество человек, подтвердивших, что описание не соответствует изображению.

В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:

1. Имя файла изображения.
2. Идентификатор описания.                 
3, 4, 5 — оценки трёх экспертов.

Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.  

В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно несколько описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.

В папке `test_images` содержатся изображения для тестирования модели.

План проекта:

1. Загрузка данных и исследовательский анализ данных
2. Подготовка данных к обучению модели
3. Обучение модели
4. Тестирование модели и демонстрация её работы
5. Общий вывод по работе

## Выводы

### Выводы по загрузке и анализу данных

1. Мы выполнили загрузку даннах: train_dataset, test_queries, test_images, ExpertAnnotations, CrowdAnnotations
- train_dataset: 5822 объектов, на 3 признака. Пропусков нет. 
- test_queries: 500 объектов, на 3 признака. Пропусков нет. 
- test_images: 100 объектов, 1 признак. Пропусков нет. 
- ExpertAnnotations: 5822 объектов, 5 признаков. Пропусков нет. 
- CrowdAnnotations: 47830 объектов, 5 признаков. Пропусков нет. 

2. Определили количество уникальных объектов в каждом датасете. 
- train_dataset изображения: 1000 из 5822
- test_queries изображения: 100 из 500
- train_dataset текст: 977 из 5822
- test_queries текст: 500 из 500
- ExpertAnnotations описания: 977 из 5822
- CrowdAnnotations описания: 1000 из 47830

3. Мы ввели медианную оценку всех экспертов для расчета агрегированной оценки экспертов. Привели целевую переменную - оценки, в диапазон [0,1], используя масштабирование min-max.

4. Построили график и определили что, большинство изображений в датасете не соответсвует описанию.

5. Мы создали новый датасет для обучения на основе имеющихся файлов данных через объединение train_dataset, ExpertAnnotations методом left, CrowdAnnotations методом outer
Мы получили датасет train_data состоящий из 51323 объектов и 5 признаков. 

6. Среди данных есть пропуски в признаках query_text, exp_norm, conf_rate, удалили их

7. Перед удалением дублей тренировочного датасета было 51323, мы нашли строк дублей 1109 и удалили их. Результирующее количество строк датасета: 50214

### Выводы по исполнению требования по ограничению обработки изображений

1. Мы создали словарь, в который записали слова, связанные с детьми и подростками
2. Создали функции для удаления запрещенных запросов, для поиска запрещенных запросов. 
3. Убрали из датафрейма все запрещенный картинки
4. Получили количество объектов в очищенном от запрещенных слов датасете: 35764

### Выводы по векторизации текстов. 

Мы сделали функцию text_to_vectors, которая предназначена для преобразования серии текстов в векторы с использованием модели DistilBERT из библиотеки Hugging Face Transformers. 
Входе её применения к train_data_clear['query_text'] и было выполнено:

1. Загрузка токенизатора и модели DistilBERT
2. Токенизация текста
3. Паддинг (выравнивание) последовательностей
4. Преобразование в тензоры PyTorch
5. Получение эмбеддингов батчами
6. Последовательности обрабатываются батчами для экономии памяти и улучшения производительности. Для каждой партии:

- Получается эмбеддинг с модели, при этом отключен градиент для экономии памяти.
- Извлекается эмбеддинг специального токена [CLS] (первый токен в каждом из эмбеддингов).
- Очищается кэш CUDA для оптимального использования памяти на GPU.
7. Объединение эмбеддингов:

Полученные эмбеддинги из всех батчей объединяются в один массив, который возвращается как результат функции.

Результиующий массив получился размером 35764, 768 и был сохранён в хранилище по пути save_path.

### Выводы по векторизации изображений. 

Мы привели фотографии в векторы с использованием предобученной модели Inception v3

1. Мы создали функцию image_to_tensor, которая выполнила операцию перевода изображений в вектор
2. Результат записали в датасет получившиц размер 35764, 2048
3. Полученный датасет сохранили в хранилище по пути: save_path

### Выводы по объединению векторов. 

1. Мы соединили вектор текста и вектор изображения для каждого объекта 
2. Таргет был сгенерирован на основе аггрегированных оценок экспертов и краудсорсинга. Таргет - оценка схожести описания и изображения, которая лежит в диапазоне от нуля до единицы.
В результате векторизации были получены вектора следующих размеров:

- Для одного описания: (768,)

- Для одного изображения: (2048,)

В результате признаковое пространство для одного объекта составило 2816 признаков.
Всего 35764 объекта

### Выводы по обучеию модели
В качестве метрики обучения был выбран RMSE
Все предсказанные значения ниже нуля будем приводить к нулю, а все предсказанные значения выше едииницы - к единице.
Разделили датасет на обучающую и тестовые выборки. 

- Линейная модель
Проверили качество работ двух линейных моделей LinearRegression и ElasticNet.
LinearRegression - показала довольно низкий результат RMSE=0.68. У ElasticNet результат лучше RMSE=0.21.
Однако ошибки этих моделей слишком большие, чтобы использовать их.
- Нейронная сеть. 
Нейронная сеть показал RMSE приблизительно 0.05 на валидационной выборке. Используем данную архитектуру для тестирования

### Тестирование модели
При проверке на тестовых данных модель показала низкое качество. В итоге, она выдавала изображения, на которых контекст сложно сказать, что схож с описанием.

Работу модели можно улучшить, пободрав большее количество валидных описаний. 
